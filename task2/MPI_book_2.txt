ULFM (User Level Failure Mitigation "Меры по смягчению последствий сбоев на уровне пользователя") 
это набор интерфейсов для стандарта MPI (Message Passing Interface), 
позволяющий приложениям продолжать работу после сбоев процессов, 
не блокироваться вечно и самостоятельно управлять восстановлением, 
сообщая об ошибках вместо автоматических действий MPI,


MPI_COMM_NULL — это специальное значение MPI, означающее “процесс не участвует в данном коммуникаторе”.
Коротко по сути:
    если comm == MPI_COMM_NULL, процесс не является членом группы;
    нельзя вызывать MPI-операции с таким коммуникатором;
    часто используется как результат MPI_Comm_split, чтобы “исключить” процесс из подкоммуникатора.

В твоём коде:
резервные процессы получают MPI_COMM_NULL для active,
они не участвуют в вычислениях, но остаются живыми в world.



MPI_MAX_ERROR_STRING - Максимальная длина строки с описанием ошибки MPI.




MPI_ERR_OTHER - Общий класс ошибки MPI — “что-то пошло не так, но не относится к стандартным категориям”.



MPIX_ERR_PROC_FAILED - ULFM-ошибка: один или несколько MPI-процессов завершились сбоем.




MPIX_ERR_REVOKED - ULFM-ошибка: коммуникатор был отозван (MPIX_Comm_revoke).
Что означает:
    коммуникации в этом коммуникаторе принудительно прерваны,
    все процессы получают ошибку и выходят из коллективных операций,
    сигнал “всем пора переходить к восстановлению”.





MPIX_Comm_revoke(world) — это ULFM-функция, которая принудительно “ломает” указанный коммуникатор у всех процессов, 
чтобы все участники одновременно узнали о сбое и перестали ждать друг друга.
Помечает коммуникатор как “отозванный” (revoked)
После этого данный коммуникатор нельзя нормально использовать для обменов.

Прерывает все текущие и будущие MPI-операции на этом коммуникаторе: MPI_    st, MPI_Barrier, MPI_Send/Recv
вернёт ошибку MPIX_ERR_REVOKED, а не будет ждать бесконечно.

Распространяется на все процессы, которые ещё живы и входят в этот коммуникатор
Даже если только один процесс вызвал MPIX_Comm_revoke, эффект увидят все остальные.




MPI_File. Тип (дескриптор) файла в MPI-IO.
Аналог: FILE* в stdio, int fd в POSIX,
но коллективный и параллельный: один MPI_File используется сразу всеми процессами коммуникатора.




MPI_MODE_CREATE. Флаг открытия файла: создать файл, если его нет.

MPI_MODE_WRONLY. Флаг открытия файла: разрешить только запись.


MPI_INFO_NULL. Пустой объект MPI_Info. “никаких специальных подсказок MPI-IO не даём”.
MPI_Info можно использовать для hint’ов файловой системе (striping, агрегация и т.д.), 
но MPI_INFO_NULL — стандартный и безопасный вариант.



MPI_BYTE. MPI-тип данных, означающий один байт без интерпретации.
Используется, когда:
    пишешь/читаешь “сырые” данные (структуры, заголовки),
    не хочешь зависеть от представления типов.



MPI_STATUS_IGNORE - “статус операции мне не нужен”.
Используется вместо MPI_Status*, когда:
    тебе не важно, сколько элементов реально записалось/прочиталось,
    ты всё равно проверяешь код возврата rc.



MPI_File_open(active, path, MPI_MODE_CREATE | MPI_MODE_WRONLY, MPI_INFO_NULL, &fh);
Коллективно открывает (или создаёт) файл path для записи всеми процессами коммуникатора active.

active - Коммуникатор, все процессы которого обязаны вызвать MPI_File_open. Только они будут участвовать в параллельном вводе-выводе.
path - Путь к файлу контрольной точки (checkpoint).
MPI_MODE_CREATE | MPI_MODE_WRONLY - Флаги открытия
&fh - Указатель, куда MPI запишет дескриптор файла (MPI_File).
rc - Код возврата:

MPI_File_open — коллективная операция: все процессы active должны войти в неё, иначе программа зависнет или вернёт ошибку.




MPI_File_write_at(fh, 0, &h, (int)sizeof(h), MPI_BYTE, MPI_STATUS_IGNORE);
Что делает (одним предложением)
Записывает структуру h в начало файла (offset = 0) как “сырые байты”, 
не меняя файловый указатель и не завися от других процессов.

Почему именно write_at, а не write???
MPI_File_write использует общий файловый указатель → нужна синхронизация.
MPI_File_write_at пишет в явное смещение, поэтому:

безопасен при параллельной записи,
каждый процесс знает, куда писать,
не мешает другим.



MPI_Barrier(active) — коллективная операция синхронизации.
“Все процессы коммуникатора active должны дойти до этого места, прежде чем кто-то пойдёт дальше”.

Каждый процесс из active вызывает MPI_Barrier.
Пока хотя бы один процесс не дошёл — никто не выйдет из барьера.
Когда дошли все — все одновременно выходят и продолжают выполнение.



MPI_Offset - Тип MPI для смещений (offset) в файле.
это целочисленный тип большой разрядности (обычно 64-бит), предназначен для адресации больших файлов (>2–4 ГБ).

Используется для:
позиции записи/чтения в файле (write_at, read_at), задания размера файла (MPI_File_set_size).



MPI_File_set_size - Коллективно устанавливает размер файла в байтах.
Что делает:
если файл меньше — расширяет его (обычно заполняя нулями),
если файл больше — усекает его до указанного размера.



rc = MPI_File_write_at_all(
        fh,              // дескриптор MPI-файла
        off,             // абсолютное смещение в файле (в байтах)
        (void*)Aloc,     // буфер в памяти
        count,           // число элементов
        MPI_FLOAT,       // тип элементов
        MPI_STATUS_IGNORE
     );
Суффикс _all означает: все процессы участвуют в операции.
Коллективно и параллельно записывает данные всех процессов в файл, 
причём каждый процесс пишет в своё место файла, заданное смещением off.
Параллельная запись
MPI-IO может:
    агрегировать запросы,
    оптимизировать порядок реальных операций записи,
    эффективно использовать параллельную ФС.




MPI_File_sync(fh);
Принудительно сбрасывает (flush) все буферы MPI-IO на устойчивое хранилище.
“Гарантирует, что данные реально записаны в файл, а не висят в буферах”.



MPI_File_read_at(
        fh,                 // дескриптор MPI-файла
        0,                  // абсолютное смещение в файле (в байтах)
        &h,                 // буфер в памяти, куда записать прочитанное
        (int)sizeof(h),     // количество элементов
        MPI_BYTE,           // тип элемента
        MPI_STATUS_IGNORE
     );
Читает sizeof(h) байт из начала файла (offset = 0) в память структуры h, не используя общий файловый указатель.

Почему используется MPI_File_read_at, а не MPI_File_read
MPI_File_read использует общий файловый указатель,
в параллельном коде это требует дополнительной синхронизации.

MPI_File_read_at:
    читает из заданного места,
    безопасен и предсказуем,
    идеально подходит для параллельного восстановления.




MPI_File_read_at_all(
        fh,                 // дескриптор MPI-файла
        off,                // абсолютное смещение в файле (в байтах)
        Aloc,               // буфер в памяти процесса
        count,              // число элементов
        MPI_FLOAT,          // тип элементов
        MPI_STATUS_IGNORE
     );
Коллективно и параллельно читает из файла локальные блоки данных всеми процессами, при этом каждый процесс читает свой участок файла, начиная со смещения off.
Все процессы коммуникатора active обязаны вызвать MPI_File_read_at_all.
Если кто-то не вызовет — будет зависание или ошибка.
и никто не выйдет, пока чтение “логически не завершено” у всех участников




MPI_Comm_split(world, color, wrank, &active);
делит один коммуникатор на несколько новых коммуникаторов (групп), 
по правилу “у кого одинаковый color — те в одной группе”.

Все процессы из world обязаны вызвать MPI_Comm_split (это коллективная операция).
MPI смотрит на значение color у каждого процесса:
    если color одинаковый → процессы попадают в один новый коммуникатор,
    если color разный → будут разные новые коммуникаторы,
    если color == MPI_UNDEFINED → процесс не попадает никуда и получит MPI_COMM_NULL.

Внутри каждой группы MPI назначает новые ранги.
Порядок рангов внутри нового коммуникатора задаёт параметр key.

world — исходный коммуникатор, который делим.
color — “в какую группу попасть”:
у тебя: color = 1 для wrank < WORK (рабочие),
MPI_UNDEFINED для остальных (резервы).

wrank — это key:
сортирует процессы внутри новой группы по их исходному рангу,
поэтому в active ранги сохраняют “естественный” порядок (0..WORK-1).
&active — сюда MPI записывает результат:
    рабочие получают валидный коммуникатор active,
    резервы получают MPI_COMM_NULL.



MPI_Bcast(&X[N - 1], 1, MPI_FLOAT, owner_last, active);
Один процесс (owner_last) рассылает значение X[N-1] всем процессам коммуникатора active.
Все процессы из active обязаны вызвать MPI_Bcast. Это коллективная операция.

Роль root (owner_last)
процесс owner_last: читает значение из своей памяти X[N-1], отправляет его другим.

Роль остальных процессов
у них X[N-1] до вызова — мусор, во время MPI_Bcast MPI записывает туда полученное значение.

Завершение
MPI_Bcast возвращается у всех процессов только после того, как: данные отправлены root’ом, данные получены всеми остальными.




MPI_Comm_set_errhandler(world, MPI_ERRORS_RETURN);
«Если в коммуникаторе world произойдёт ошибка — 
НЕ завершай программу автоматически, а верни код ошибки из MPI-вызова».


MPIX_Comm_shrink(world, &world2);
Создаёт новый коммуникатор world2, 
в который входят только живые процессы из world, автоматически исключая все упавшие.
Он не сохраняет старые ранги



MPI_Gather(&my_initial, 1, MPI_INT, surv_old, 1, MPI_INT, 0, world); коллективная операция сбора данных:
каждый процесс отправляет по одному значению → процесс с рангом 0 собирает их в массив.
Все процессы из world обязаны вызвать MPI_Gather.

Каждый процесс отправляет:
&my_initial, 1, MPI_INT
Процесс world_rank == 0:
    получает массив surv_old[0..world_size-1], элементы упорядочены по новым рангам world.




